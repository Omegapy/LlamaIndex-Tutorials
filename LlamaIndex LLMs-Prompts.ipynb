{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# LlamaIndex LLMs-Prompts : LlamaIndex Intro. Tutorial\n",
    "Alejandro Ricciardi (Omegapy)\n",
    "created date: 12/23/2023 GitHub: https://github.com/Omegapy\n",
    "\n",
    "Projects Description:\n",
    "Testing an LLM using the primary prompt templates used in LlamaIndex.\n",
    "LlamaIndex LLMs-Prompts tutorial base on LlamaIndex Bottoms-Up Development video series.\n",
    "\n",
    "- Initialization \n",
    "    - API Keys\n",
    "    - LLM Init.\n",
    "    - Load File\n",
    "\n",
    "- Templates\n",
    "    - Context\n",
    "    - Refined Context - More Context\n",
    "\n",
    "- Chat\n",
    "    - Simulate a ChatBot that can answer questions about llama-index.\n",
    "\n",
    "credit: LlamaIndex https://www.youtube.com/watch?v=p0jcvGiBKSA&t=201s"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bcef53ed2feeb497"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### API Keys\n",
    "This project you require API keys from: OpenAI: https://openai.com/ "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b25039ec7017c7c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables API Keys\n",
    "\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "load_dotenv(find_dotenv()) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T15:03:36.777798700Z",
     "start_time": "2023-12-26T15:03:36.774262Z"
    }
   },
   "id": "90c5df019088e481",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LlmaIndex \n",
    "llm initialization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8b3560e5cdd9cc3"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f68644c659fcd9cb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from llama_index.llms import OpenAI\n",
    "llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T15:08:34.944684Z",
     "start_time": "2023-12-26T15:08:32.203540200Z"
    }
   },
   "id": "ac97eb8575e86bb2",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Document"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69d216f8ce96f8ae"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open(\"docs/getting_started/starter_example.md\", \"r\") as f:\n",
    "    text = f.read()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T15:30:35.258283100Z",
     "start_time": "2023-12-26T15:30:35.255143600Z"
    }
   },
   "id": "a9a74d1a2f31d8f0",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Templates \n",
    "Usage Pattern - Defining a custom prompt: \n",
    "https://docs.llamaindex.ai/en/stable/module_guides/models/prompts/usage_pattern.html#template-variable-mappings\n",
    "\n",
    "`text_qa_template` -> initial answers. (context)\n",
    "`refine_template`  -> refining an existing answer when all the text does not fit into one LLM call. (more context)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9cd44b13c03a1e3a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from llama_index import Prompt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T15:18:51.222198Z",
     "start_time": "2023-12-26T15:18:51.215678600Z"
    }
   },
   "id": "30929fb2af1cbab3",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "text_qa_template = Prompt(\n",
    "    \"Context information is below.\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Given the context information and not prior knowledge, \"\n",
    "    \"answer the question: {query_str}\\n\"\n",
    ")\n",
    "\n",
    "refine_template = Prompt(\n",
    "    \"We have the opportunity to refine the original answer \"\n",
    "    \"(only if needed) with some more context below.\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"{context_msg}\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"Given the new context, refine the original answer to better \"\n",
    "    \"answer the question: {query_str}. \"\n",
    "    \"If the context isn't useful, output the original answer again.\\n\"\n",
    "    \"Original Answer: {existing_answer}\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T15:19:26.065991900Z",
     "start_time": "2023-12-26T15:19:26.056973100Z"
    }
   },
   "id": "db7c61cb65541a1",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Context\n",
    "Prompted Questions - AI Generated answers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "950ef05880e604b5"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To install LlamaIndex, you need to follow the installation steps provided in the \"installation.md\" file.\n"
     ]
    }
   ],
   "source": [
    "question = \"How can I install llama-index?\"\n",
    "prompt = text_qa_template.format(context_str=text, query_str=question)\n",
    "response = llm.complete(prompt)\n",
    "print(response.text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T15:31:35.731927300Z",
     "start_time": "2023-12-26T15:31:33.905461Z"
    }
   },
   "id": "cf9a31a275843f7d",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To create an index using LlamaIndex, you need to follow these steps:\n",
      "\n",
      "1. Download the LlamaIndex repository by cloning it from GitHub using the command: `$ git clone https://github.com/jerryjliu/llama_index.git`\n",
      "\n",
      "2. Navigate to the downloaded repository using the command: `$ cd llama_index`\n",
      "\n",
      "3. Go to the `examples/paul_graham_essay` folder using the command: `$ cd examples/paul_graham_essay`\n",
      "\n",
      "4. Create a new Python file and import the necessary classes from LlamaIndex:\n",
      "\n",
      "```python\n",
      "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
      "```\n",
      "\n",
      "5. Load the documents that you want to index using the `SimpleDirectoryReader` class:\n",
      "\n",
      "```python\n",
      "documents = SimpleDirectoryReader('data').load_data()\n",
      "```\n",
      "\n",
      "6. Build the index using the `VectorStoreIndex` class:\n",
      "\n",
      "```python\n",
      "index = VectorStoreIndex.from_documents(documents)\n",
      "```\n",
      "\n",
      "Now you have created an index over the documents in the specified folder.\n",
      "\n",
      "Note: The example assumes that the documents are stored in the `data` folder. You can modify the code accordingly to point to your desired folder.\n"
     ]
    }
   ],
   "source": [
    "question = \"How do I create an index?\"\n",
    "prompt = text_qa_template.format(context_str=text, query_str=question)\n",
    "response = llm.complete(prompt)\n",
    "print(response.text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T15:32:26.607104100Z",
     "start_time": "2023-12-26T15:32:16.795565200Z"
    }
   },
   "id": "4e3e4617750da9c",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
      "\n",
      "documents = SimpleDirectoryReader('data').load_data()\n",
      "index = VectorStoreIndex.from_documents(documents)\n",
      "```"
     ]
    }
   ],
   "source": [
    "question = \"How do I create an index? Write your answer using only code.\"\n",
    "prompt = text_qa_template.format(context_str=text, query_str=question)\n",
    "response_gen = llm.stream_complete(prompt)\n",
    "for response in response_gen:\n",
    "    print(response.delta, end=\"\")\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T15:32:50.921277800Z",
     "start_time": "2023-12-26T15:32:48.837606900Z"
    }
   },
   "id": "f431bb638932ce06",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "### More Context - Refine Template "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6f6fb866ffafee9"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To create an index using LlamaIndex, you can follow these steps:\n",
      "\n",
      "```python\n",
      "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
      "\n",
      "# Step 1: Load the documents\n",
      "documents = SimpleDirectoryReader('data').load_data()\n",
      "\n",
      "# Step 2: Build the index\n",
      "index = VectorStoreIndex.from_documents(documents)\n",
      "\n",
      "# Step 3: Persist the index to disk\n",
      "index.storage_context.persist()\n",
      "\n",
      "# Step 4: Reload the index from disk\n",
      "from llama_index import StorageContext, load_index_from_storage\n",
      "\n",
      "# rebuild storage context\n",
      "storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")\n",
      "# load index\n",
      "index = load_index_from_storage(storage_context)\n",
      "```\n",
      "\n",
      "Make sure you have already installed LlamaIndex and have the necessary dependencies.\n"
     ]
    }
   ],
   "source": [
    "question = \"How do I create an index? Write your answer using only code.\"\n",
    "existing_answer = \"\"\"To create an index using LlamaIndex, you need to follow these steps:\n",
    "\n",
    "1. Download the LlamaIndex repository by cloning it from GitHub.\n",
    "2. Navigate to the `examples/paul_graham_essay` folder in the cloned repository.\n",
    "3. Create a new Python file and import the necessary modules: `VectorStoreIndex` and `SimpleDirectoryReader`.\n",
    "4. Load the documents from the `data` folder using `SimpleDirectoryReader('data').load_data()`.\n",
    "5. Build the index using `VectorStoreIndex.from_documents(documents)`.\n",
    "6. To persist the index to disk, use `index.storage_context.persist()`.\n",
    "7. To reload the index from disk, use the `StorageContext` and `load_index_from_storage` functions.\n",
    "\n",
    "Note: This answer assumes that you have already installed LlamaIndex and have the necessary dependencies.\"\"\"\n",
    "prompt = refine_template.format(context_msg=text, query_str=question, existing_answer=existing_answer)\n",
    "response = llm.complete(prompt)\n",
    "print(response.text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T15:35:55.046036200Z",
     "start_time": "2023-12-26T15:35:48.817904100Z"
    }
   },
   "id": "d16ab95f313c24d2",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Chat\n",
    " The LLM also has a `chat` method that takes in a list of messages, to simulate a chat session."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d3a33942b493a29"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "27eef851b80db8b1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from llama_index.llms import ChatMessage"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T16:01:01.310468500Z",
     "start_time": "2023-12-26T16:01:01.305456400Z"
    }
   },
   "id": "1023edd47c481653",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: To create an index, you can follow these general steps:\n",
      "\n",
      "1. Determine the purpose and scope of your index: Decide what information you want to include in your index and what it will be used for. This will help you define the scope and structure of your index.\n",
      "\n",
      "2. Identify the items to be indexed: Determine the specific items or topics that you want to include in your index. For example, if you are creating an index for a book, you might want to index chapters, sections, and important concepts.\n",
      "\n",
      "3. Create a list of index terms: Compile a list of terms or keywords that represent the items you identified in the previous step. These terms should be concise and specific to help users find the information they need.\n",
      "\n",
      "4. Organize the index terms: Group the index terms into logical categories or sections. This will help users navigate the index more easily and find relevant information faster.\n",
      "\n",
      "5. Assign page numbers or locations: For each index term, determine the page number or location where the term can be found. This is typically done by scanning the document or source material and noting the relevant page numbers or locations.\n",
      "\n",
      "6. Format and design the index: Decide on the format and design of your index. You can use software tools like Microsoft Word or dedicated indexing software to create a professional-looking index. Consider factors like font size, layout, and any additional formatting elements.\n",
      "\n",
      "7. Proofread and revise: Review your index for accuracy, consistency, and completeness. Make sure all index terms are correctly assigned to the appropriate page numbers or locations.\n",
      "\n",
      "8. Include the index in your document: Once you are satisfied with your index, insert it into your document or publication. Ensure that it is placed in a prominent location, such as at the end of a book or at the beginning of a report.\n",
      "\n",
      "Remember, the specific steps may vary depending on the type of index you are creating and the tools you are using.\n"
     ]
    }
   ],
   "source": [
    "chat_history = [\n",
    "    ChatMessage(role=\"system\", content=\"You are a helpful QA chatbot that can answer questions about llama-index.\"),\n",
    "    ChatMessage(role=\"user\", content=\"How do I create an index?\"),\n",
    "]\n",
    "\n",
    "response = llm.chat(chat_history)\n",
    "print(response.message)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T16:03:51.300615100Z",
     "start_time": "2023-12-26T16:03:35.255566800Z"
    }
   },
   "id": "2b857f57c97eb73e",
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
